{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f1bc7b-63d0-497d-8937-ea16faafbcff",
   "metadata": {},
   "source": [
    "In this session (held on 9-8-2023), we started working with Anaconda on our own machines. We had to setup a virtual environment, which took some time, and then started looking at two libraries for working with tabular data in python, namely, `pandas` and `polars`. The following code block imports the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee76f12-3290-4db1-9b68-2d50a039ae26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a807c42d-f144-450f-b7cb-e732730b72a7",
   "metadata": {},
   "source": [
    "You can see what version of a library you are running by accessing the `.__version__` attribute of an imported library. The following code block shows how we can pront the version of the `polars` library that we are using. Although your version may differ from the one shown, you should note that the code was developed using the version shown and you may run into some differences, even errors, if your version differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb24bb2-7c74-4737-9a87-0de7b7a2d5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afdcb47-bbba-40f1-85b5-89bd7411dd1e",
   "metadata": {},
   "source": [
    "The following code block shows the version of `pandas` library that is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a0acad-18e0-48ec-863c-05300e3f10c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d3349-1765-4b99-96f1-e861c86d8b0a",
   "metadata": {},
   "source": [
    "We will now look at a few differences between the two imported libraries in terms of computational speed, memory usage, and syntax. We will start by looking at the computational efficiency of data ingestion. The following code block uses the `%%timeit` *magic* method available in Jupyter to estimate the average time required for `pandas` to load the data contained in the `churn.csv` file using the `pandas` `read_csv` method. **Note**: this code expects that the `churn.csv` file is located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcd69ae-b8c9-4e7e-ac87-fd70015d41f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.6 ms ± 2.83 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "pd.read_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ebcc5-d589-4a55-8df7-97d3e1bc979e",
   "metadata": {},
   "source": [
    "The following code block uses the `%%timeit` *magic* method to estimate the average time required for `polars` to load the data contained in the `churn.csv` file using the `polars` `read_csv` method. Although times will differ based on the machine the code is ran on, the time required for `polars` should be significantly lower than that required for `pandas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d396ec9f-9bb2-4f81-8a58-5e87eb94e366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.44 ms ± 22.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "pl.read_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3b12b-d1d4-4193-be84-05252432e84f",
   "metadata": {},
   "source": [
    "The following code block reads the data and stores it two objects: 1) a `pandas` `DataFrame` named `data_pd` and 2) a `polars` `DataFrame` named `data_pl`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ef07e7-f8ab-476e-9229-5adda877fb24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv('churn.csv')\n",
    "data_pl = pl.read_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52d10a-450a-409e-98d0-42b0610f8923",
   "metadata": {},
   "source": [
    "The following code block uses the `memory_usage` method of a `pandas` `DataFrame` to estimate the amount of memory occupied by the `data_pd` object in bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c9aebe2-f108-49b3-a277-ee1ad51fae95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8166479"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507f096-38b0-4132-b5ee-520f5f2eb93c",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following code block uses the `estimated_size` method of a `polars` `DataFrame` to estimate the amount of memory occupied by the `data_pl` object in bytes. We observe that the `polars` `DataFrame` occupies significantly less memory than the `pandas` `DataFrame`, even though it is storing the same data. **In general, `polars` tends to be significantly more efficient than `pandas` with respect to both computational time and memory usage. This is an artifact of the way that it interacts with system resources and its usage of the Apache Arrow Columnar specification for data storage (see https://arrow.apache.org/docs/format/Columnar.html for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6bd08d4-6e1c-496e-8b31-aac117937c90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1914043"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pl.estimated_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b7228-72f5-4bc2-a0ab-3a72305daf05",
   "metadata": {},
   "source": [
    "A very common task when working with data is a `groupby-aggregation` sequence where some operation is performed across groups of data. The following code block shows such an aggregation using the `pandas` object. Specifically, we are grouping on unique values in the `Partner` column and getting the number of unique values for the `customerID` column for each of the `Partner` groups. **Note**: recall that you could run `data_pd.head()` to see the first five rows of the `pandas` `DataFrame`, which would include the column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d7072b6-9129-4402-bd5e-9f724094d73c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_customers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partner</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>3641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>3402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_customers\n",
       "Partner                  \n",
       "No                   3641\n",
       "Yes                  3402"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.groupby('Partner').agg(\n",
    "    unique_customers=('customerID', 'nunique')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7c5cfd-466e-4ff6-8584-85e9b47b59b4",
   "metadata": {},
   "source": [
    "The following code block performs the same operation on the `polars` object. Notice that there are some differences in the syntax. First, instead of `groupby`, `polars` uses `group_by`. Also, the way that we specify the column aggregation and its label is different (i.e., `unique_customers=('customerID', 'nunique')` in `pandas` **vs.** `pl.col('customerID').n_unique().alias('unique_customers')` in `polars`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fdcd9ac-8945-4236-8280-a40e1a66b36b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Partner</th><th>unique_customers</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;No&quot;</td><td>3641</td></tr><tr><td>&quot;Yes&quot;</td><td>3402</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌─────────┬──────────────────┐\n",
       "│ Partner ┆ unique_customers │\n",
       "│ ---     ┆ ---              │\n",
       "│ str     ┆ u32              │\n",
       "╞═════════╪══════════════════╡\n",
       "│ No      ┆ 3641             │\n",
       "│ Yes     ┆ 3402             │\n",
       "└─────────┴──────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pl.group_by('Partner').agg(\n",
    "    pl.col('customerID').n_unique().alias('unique_customers')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373df34-47ab-4a64-9a12-461813b36530",
   "metadata": {},
   "source": [
    "The following code block times a more complex filtering operation in `pandas`. Specifically, we:\n",
    "1. define a mask that determines rows where the value in the `tenure` column is greater than or equal to 12 (`tenure_mask`),\n",
    "2. define a mask that determines rows where the value in the `PhoneService` column is `Yes` (`phone_service_mask`),\n",
    "3. combines the `tenure_mask` and `phone_service_mask` objects to get a mask for rows where the value in the `tenure` column is greater than or equal to 12 **and** the value in the `PhoneService` column is `Yes` (`combined_mask`), and\n",
    "4. gets the number of unique customer IDs by value in the `Partner` column for the data filtered by the `combined_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c3d3d86-29e1-46ee-a1f5-65f87c2db29c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.14 ms ± 63.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "tenure_mask = data_pd['tenure'] >= 12\n",
    "phone_service_mask = data_pd['PhoneService'] == 'Yes'\n",
    "combined_mask = tenure_mask & phone_service_mask\n",
    "data_pd[combined_mask].groupby('Partner').agg(\n",
    "    unique_customers=('customerID', 'nunique')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a25151e-c6a3-4268-994d-f78cdb9062e5",
   "metadata": {},
   "source": [
    "The following code block performs the same sequence of operations using the `polars` object. Note that when we used `pandas`, we created several temporary objects along the way to completing our task. In `polars`, we can specify a more *functional* sequence of operations, where method calls are *chained* together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf59c7b2-2765-4181-a802-b79f17711505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.88 ms ± 276 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "data_pl.filter(\n",
    "    pl.col('tenure') >= 12\n",
    ").filter(\n",
    "    pl.col('PhoneService') == 'Yes'\n",
    ").group_by('Partner').agg(\n",
    "    pl.col('customerID').n_unique().alias('unique_customers')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a414d-a4ab-4ae5-b030-e777a565c52e",
   "metadata": {},
   "source": [
    "In our previous `pandas` and `polars` implementations, we (the user) was controlling the order of operations on the data by the sequence we applied them. However, there has been significant research effort put into the development of *optimizers* that can determine the best sequence of operations for data manipulations that can significantly reduce computational time. The `polars` library has such an optimizer built in. To let `polars` use its optimizer, we can specify that we want the sequence of operations evaluated in a `lazy` fashion. By doing so, we are telling `polars` what we want to do, but letting the library figure out the best way to accomplish it. The following code block times such a `lazy` implementation of the previous code block. Note the `.lazy()` call towards the beginning and the `.collect()` call at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1276d3c9-aa55-4b78-b32f-55d3e41a52f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701 µs ± 60.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "data_pl.lazy().filter(\n",
    "    pl.col('tenure') >= 12\n",
    ").filter(\n",
    "    pl.col('PhoneService') == 'Yes'\n",
    ").group_by('Partner').agg(\n",
    "    pl.col('customerID').n_unique().alias('unique_customers')\n",
    ").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
